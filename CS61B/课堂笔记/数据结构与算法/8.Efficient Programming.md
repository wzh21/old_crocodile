# 8.1 Encapsulation, API's. ADT's

### Efficient Programming

“An engineer will do for a dime what any fool will do for a dollar” -- Paul Hilfinger“ 一个工程师一毛钱就能做任何傻瓜一美元就能做的事”——保罗·希尔芬格

Efficiency comes in two flavors(风格，特色):

**1.) ==Programming cost.==**

- **How long does it take to develop your programs?**
- **How easy is it to read, modify, and maintain your code?**

**2.) ==Execution cost==(starting next week).**

- **How much time does your program take to execute?**
- **How much memory does your program require?**

*Today, we will be focusing on how to reduce programming cost.* Of course, want to keep programming costs low, both so we can write code faster and so we can have less frustrated people which will also help us write code faster (people don't code very fast when they are frustrated). 今天，我们将关注如何降低编程成本。当然，我们希望保持编程成本低，这样既可以更快地编写代码，也可以减少沮丧的人，这也有助于我们更快地写代码（人们在沮丧时不会很快地编写代码）。

Some helpful Java features discussed in 61B:

- **Packages.**
  - Good: Organizing, making things package private
  - Bad: Specific
- **Static type checking.**
  - Good: Checks for errors early , reads more like a story
  - Bad: Not too flexible, (casting)
- **Inheritance.**
  - Good: Reuse of code
  - Bad: “Is a”, **the path of debugging gets annoying**, can’t instantiate, implement every method of an interface

We will explore some new ways in this chapter!我们将在本章中探索一些新的方法！

## Encapsulation 封装

We will first define a few terms: 我们将首先定义几个术语：

- ==**Module(模块):** A set of methods that work together as a whole to perform some task or set of related tasks.==
- ==**Encapsulated:** A module is said to be encapsulated **if its implementation is completely hidden, and it can be accessed only through a documented interface.**==

## API's

**An API(Application Programming Interface) of an ADT is the list of constructors and methods and a short description of each.**

API consists of syntactic(语法的) and semantic(语义的) specification.

- **Compiler verifies that syntax is met. 编译器验证是否符合语法**
  - AKA(又称作), **everything specified in the API is present. API中指定的所有内容都存在.**
- **Tests help verify that semantics are correct.**
  - AKA **everything actually works the way it should.**
  - Semantic specification usually written out in English (possibly including usage examples). Mathematically precise formal specifications are somewhat possible but not widespread.

## ADT's

==ADT's (Abstract Data Structures) are high-level types that are defined by their **behaviors**, not their implementations.==

> **i.e.) Deque in Proj1 was an ADT that had certain behaviors (addFirst, addLast, etc.). But, the data structures we actually used to implement it was ArrayDeque and LinkedListDeque**

Some ADT's are actually special cases of other ADT's. For example, Stacks and Queues are just lists that have even more specific behavior. ==**有些ADT实际上是其他ADT的特例**==。例如，堆栈和队列只是具有更具体行为的列表。

**Exercise 8.1.1**
Write a Stack class using a Linked List as its underlying data structure. You only need to implement a single function: push(Item x). Make sure to make the class generic with "Item" being the generic type!使用linked list作为其基础数据结构编写Stack类。您只需要实现一个函数：push（项x）。确保类是泛型的，“Item”是泛型类型！

你可能用几种不同的方式写了它。让我们看看三种流行的解决方案：

```java
public class ExtensionStack<Item> extends LinkedList<Item> {
    public void push(Item x) {
        add(x);
    }
}
```

**==This solution uses *extension*==. it simply borrow the methods from `LinkedList<Item>` and uses them as its own.**

```java
public class DelegationStack<Item> {
    private LinkedList<Item> L = new LinkedList<Item>();
    public void push(Item x) {
        L.add(x);
    }
}
```

==**This approach uses Delegation(委派)**==. **It creates a Linked List object and calls its methods to accomplish its goal.**

```java
public class StackAdapter<Item> {
    private List L;
    public StackAdapter(List<Item> worker) {
        L = worker;
    }

    public void push(Item x) {
        L.add(x);
    }
}
```

This approach is similar to the previous one, except it can use any class that implements the **List** interface (Linked List, ArrayList, etc). 这种方法与前一种(第二种)类似，只是它可以使用实现**List**接口的任何类（LinkedList、ArrayList等）。

==**Warning**: be mindful of the difference between **"is-a" and "has-a"** relationships.==

- A cat has-a claw
- A cat is-a feline

==Earlier in the section define that delegation is accomplished by passing in a class while extension is defined as inheriting (just because it may be hard to notice at first glance)==.  本节前面的定义是，委托是通过传入类来完成的，而扩展是定义为继承的（因为乍一看可能很难注意到）。

==**Delegation vs Extension:**== Right now it may seem that Delegation and Extension are pretty much interchangeable; however, there are some important differences that must be remembered when using them.现在看来，授权和扩展似乎可以互换；然而，**在使用它们时，必须记住一些重要的区别。**

==**Extension tends to be used when you know what is going on in the parent class. In other words, you know how the methods are implemented**==. Additionally, **with extension, you are basically saying that the class you are extending from acts similarly to the one that is doing the extending.** On the other hand, Delegation is when you do not want to consider your current class to be a version of the class that you are pulling the method from. **当您知道父类中发生了什么时，通常会使用扩展。换句话说，您知道这些方法是如何实现的**。此外，**对于扩展，您基本上是说您要扩展的类的行为与正在进行扩展的类类似。另一方面，委派是指您不想将当前类视为从中提取方法的类的版本。**

Views: Views are an alternative representation of an existed object. Views essentially limit the access that the user has to the underlying object. However, changes done through the views will affect the actual object. 视图：视图是现有对象的替代表示。视图本质上限制了用户对底层对象的访问。但是，通过视图所做的更改将影响实际对象。

```java
/** Create an ArrayList. */
List<String> L = new ArrayList<>();
/** Add some items. */
L.add(“at”); L.add(“ax”); …
```

Say you only want a list from index 1 and 4. Then you can use a method called sublist do this by the following and you will 假设您只需要索引1和4中的列表。然后您可以使用一个名为sublist的方法。通过以下操作，您将

```java
/** subList me up fam. */
List<String> SL = l.subList(1, 4);
/** Mutate that thing. */
SL.set(0, “jug”);
```

Now why is this useful? Well say we want to reverse only part of the list. For example in the below image, we would want to reverse ax ban bat in the above picture.为什么这有用？好吧，我们只想反转列表的一部分。例如，在下图中，我们希望反转上图中的ax ban bat。

![reverse](https://joshhug.gitbooks.io/hug61b/content/assets/reverse_list1.png)

The most intuitive way is to create a method that takes in a list object and the indices which should be reversed. However, this can be a bit painful because we add some extraneous logic.最直观的方法是创建一个方法，该方法接受一个列表对象和应该反转的索引。然而，这可能有点痛苦，因为我们添加了一些无关的逻辑。

To get around doing this, we can just create a general reverse function that takes in a list and reverses that list. Because views mutates the underlying object that it represents, we can create a sublist like earlier and reverse the sublist. The end result would actually mutate the actual list and not the copy.为了避免这样做，我们可以创建一个通用的反转函数，它接受一个列表并反转该列表。因为视图改变了它所代表的底层对象，所以我们可以像前面一样创建一个子列表并反转子列表。最终结果实际上会改变实际列表，而不是副本。
![img](https://joshhug.gitbooks.io/hug61b/content/assets/reverse_list2.png)

This is all fine and dandy. However, it lends itself to an issue. You are claiming that you can give a list object that when manipulated, can affect the original list object- that’s a bit weird. Just thinking “How do you return an actual List but still have it affect another List?” is a bit confusing. Well the answer is access methods.为了避免这样做，我们可以创建一个通用的反转函数，它接受一个列表并反转该列表。因为视图改变了它所代表的底层对象，所以我们可以像前面一样创建一个子列表并反转子列表。最终结果实际上会改变实际列表，而不是副本。

The first thing to notice is that the sublist method returns a list type. Additionally, there is a defined class called Sublist which extends AbstractList. Since Abstract List it implements the List interface it and Sublist are List types.首先要注意的是，sublist方法返回一个列表类型。此外，还有一个名为Sublist的定义类，它扩展了AbstractList。由于Abstract List实现了List接口，所以它和Sublist是List类型。

```java
List<Item> sublist(int start, int end){
    Return new this.Sublist(start,end);
}
```

This first thing to notice from the above code is that subList returns a List type.从上面的代码中首先要注意的是，subList返回List类型。

```java
Private class Sublist extends AbstractList<Item>{
    Private int start end;
    Sublist(inst start, int end){...}
}
```

Now the reason the sublist function returns a List is because the class SubList extends AbstractList. Since AbstractList implements the List interface both it and Sublist are List Types.现在，子列表函数返回List的原因是因为sublist类扩展了AbstractList。由于AbstractList实现了List接口，因此它和Sublist都是列表类型。

```java
public Item get(int k){return AbstractList.this.get(start+k);}
public void add(int l, Item x){AbstractList.this.add(start+k, x); end+=1}
```

An observation that should be made is that getting the kth item from our sublist is the same as getting the the kth item from our original list with an offset equal to our start index. Because we are using a get method of our outer class (the most parent one) we change our original list.需要注意的是，从子列表中获取第k项与从原始列表中获取偏移量等于起始索引的第k项相同。因为我们正在使用外部类（最父类）的get方法，所以我们更改了原始列表。

Similarly, adding an element to our sublist is the same as adding an element to our original list with an offset equal to the start index of the sublist.类似地，向子列表中添加元素与向原始列表中添加偏移量等于子列表起始索引的元素相同。

**The Takeaway:**

- APIs are pretty hard to design; however, having a coherent design philosophy can make your code much cleaner and easier to deal with**.API很难设计；然而，拥有一个连贯的设计理念可以使代码更清晰、更容易处理。**
- Inheritance is tempting to use frequently, but it has problems and should be use sparingly, only when you are certain about attributes of your classes (both those being extended and doing the extending).**==继承很容易被频繁使用，但它有问题，应该谨慎使用，只有当您确定类的属性（包括正在扩展的属性和正在进行扩展的属性）时。==**



# 8.2 Asymptotics I 渐进级数/渐进理论

## Asymptotics I: An Introduction to Asymptotic Analysis

我们可以从两个不同的角度考虑编写高效程序的过程：

1. **==Programming Cost==**

   (everything in the course up to this date)

   1. How long does it take for you to develop your programs?
   2. How easy is it to read or modify your code?
   3. **How maintainable is your code? (very important — much of the cost comes from maintenance and scalability, not development!)代码的可维护性如何？（非常重要-大部分成本来自维护和可扩展性，而不是开发！）**
   
2. **==Execution Cost==**

   (everything in the course from this point on)

   1. **Time complexity**: How much time does it take for your program to execute?
2. **Space complexity**: How much memory does your program require?

### Example of Algorithm Cost

Objective: Determine if a *sorted* array contains any duplicates.

**Silly Algorithm**: Consider ***every*** pair, returning true if any match!

**Better Algorithm:** Take advantage of the ***sorted*** nature of our array.

- We know that if there are duplicates, they must be next to each other.
- Compare neighbors: return true first time you see a match! If no more items, return false.

我们可以看到，与Better算法相比，Silly算法似乎做了更多不必要的冗余工作。但还有多少工作呢？**我们如何实际量化或确定程序的效率？本章将为您提供比较各种算法效率的正式技术和工具！**

### Runtime Characterization 运行时分析

To investigate these techniques, we will be characterizing the runtimes of the following two functions, dup1 and dup2. These are the two different ways of finding duplicates we discussed above.为了研究这些技术，我们将分析以下两个函数dup1和dup2的运行时。这是我们上面讨论的两种不同的查找重复项的方法。

Things to keep in mind about our characterizations:关于我们的分析，请记住：

- They should be simple and mathematically rigorous.**它们应该简单且数学严谨。**
- They should also clearly demonstrate the superiority of dup2 over dup1.**他们还应该清楚地证明dup2优于dup1。**

```java
//Silly Duplicate: compare everything
public static boolean dup1(int[] A) {  
  for (int i = 0; i < A.length; i += 1) {
    for (int j = i + 1; j < A.length; j += 1) {
      if (A[i] == A[j]) {
         return true;
      }
    }
  }
  return false;
}

//Better Duplicate: compare only neighbors
public static boolean dup2(int[] A) {
  for (int i = 0; i < A.length - 1; i += 1) {
    if (A[i] == A[i + 1]) { 
      return true; 
    }
  }
  return false;
}
```

### Techniques for Measuring Computational Cost

**Technique 1**: Measure execution time in seconds using a client program (i.e. actually seeing how quick our program runs in physical seconds) **技巧1**：使用客户端程序以秒为单位测量执行时间（即实际查看程序在物理秒内的运行速度）

*Procedure*

- Use a physical stopwatch(秒表)
- Or, Unix has a built in `time` command that measures execution time.
- Or, Princeton(普林斯顿大学) Standard library has a `stopwatch` class

*Observations* 观察

- As our input size increases, we can see that `dup1` takes a longer time to complete, whereas `dup2` completes at relatively around the same rate.随着输入大小的增加，我们可以看到“dup1”需要更长的时间来完成,而“dup2”则以相对相同的速度完成。

*Pros vs. Cons*

- Pros: Very easy to measure (just run a stopwatch). Meaning is clear (look at the actual length of time it takes to complete).

  优点：非常容易测量（只需运行秒表）。意思很清楚（看看完成所需的实际时间）。

- Cons: May take a lot of time to test. Results may also differ based on what kind of machine, compiler, input data, etc. you’re running your program with.

  优点：非常容易测量（只需运行秒表）。意思很清楚（看看完成所需的实际时间）。

  > pro and con源自于拉丁文短语“pro et contra”，意思是for and against赞成或反对。

那么，这种方法如何符合我们的目标呢？这很简单，所以很好，**但在数学上并不严格。此外，基于机器、编译器、输入等的差异意味着结果可能无法清楚地证明dup1和dup2之间的关系。**

> ==**方法一会依赖于特定的及其的性能, 编译器的类型,版本等等, 在数学上并不严格**==

#### Technique 2

**Technique 2A**: Count possible operations for an array of size N = 10,000.

```java
for (int i = 0; i < A.length; i += 1) {
  for (int j = i+1; j < A.length; j += 1) {
    if (A[i] == A[j]) {
       return true;
    }
  }
}
return false;
```

*Procedure*

- Look at your code and the various operations that it uses (i.e. assignments, incrementations, etc.)

  查看代码及其使用的各种操作（例如赋值、递增等）

- Count the number of times each operation is performed.**查看代码及其使用的各种操作（例如赋值、递增等）**

*Observations*

- Some counts get tricky to count.有些数字很难计算。
- How did we get some of these numbers? It can be complicated and tedious.我们是怎么得到这些数字的？它可能是复杂和乏味的。

*Pros vs. Cons*

- 优点：机器独立（大部分）。模型中捕获的输入相关性。

- 缺点：计算麻烦。数组大小是任意的（我们计算了N=10000-但对于较大的N呢？对于较小的N？这些值有多少？）。操作数不能告诉您执行某个操作所需的实际时间（有些操作可能比其他操作执行得更快）。

所以，也许这一个解决了我们在上面计时模拟中的一些缺点，但它有自己的问题。

**Technique 2B**: Count possible operations in terms of input array size N (symbolic counts)  根据输入数组大小N（符号计数）计算可能的操作

*Pros vs. Cons*

- Pros: Still machine independent (just counting the number of operations still). Input dependence still captured in model. But now, it tells us how our algorithm scales as a function of the size of our input.优点：仍然与机器无关（只需计算操作次数）。模型中仍捕捉到输入相关性。但现在，它告诉了我们算法如何根据输入大小进行缩放。
- Cons: Even more tedious to compute. Still doesn’t tell us the actual time it takes!缺点：计算起来更乏味。仍然没有告诉我们实际需要的时间！

------

**Checkpoint:** Applying techniques 2A and B to `dup2`

- Come up with counts for each operation, for the following code, with respect to N.
- Predict the ***rough*** magnitudes of each one!

```java
for (int i = 0; i < A.length - 1; i += 1){
  if (A[i] == A[i + 1]) { 
    return true; 
  }
}
return false;
```

| **operation**       | **symbolic count** | **count, N=10000** |
| :------------------ | :----------------- | :----------------- |
| **i = 0**           | **1**              | **1**              |
| **less than (<)**   |                    |                    |
| **increment (+=1)** |                    |                    |
| **equals (==)**     |                    |                    |
| **array accesses**  |                    |                    |

**Answer**:

| **operation**       | **symbolic count 符号计数** | **count, N=10000** |
| :------------------ | :-------------------------- | :----------------- |
| **i = 0**           | 1                           | 1                  |
| **less than (<)**   | 0 to N                      | 0 to 10000         |
| **increment (+=1)** | 0 to N - 1                  | 0 to 9999          |
| **equals (==)**     | 1 to N - 1                  | 1 to 9999          |
| **array accesses**  | 2 to 2N - 2                 | 2 to 19998         |

Note: It's okay if you were slightly off — as mentioned earlier, you want ***rough*** estimates.

### Checkpoint

**Checkpoint**: Now, considering the following two filled out tables, which algorithm seems better to you and why? `dup1`

<img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230201203708355.png" alt="image-20230201203708355" style="zoom:33%;" />

### Answer (and Why Scaling Matters)

![image-20230201203732590](C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230201203732590.png)

> parabolas:抛物线.

---

### Asymptotic Behavior 渐进性

在大多数情况下，我们只关心非常大的N（渐近行为）会发生什么。我们想考虑哪种类型的算法最适合处理大量数据，例如下面列出的示例：

- Simulation of billions of interacting particles数十亿相互作用粒子的模拟
- Social network with billions of users拥有数十亿用户的社交网络
- Encoding billions of bytes of video data编码数十亿字节的视频数据

Algorithms that scale well (i.e. look like lines) have better asymptotic runtime behavior than algorithms that scale relatively poorly (i.e. looks like parabolas).缩放良好（即看起来像直线）的算法比缩放相对较差（即看起来类似抛物线）的算法具有更好的渐近运行时行为。

#### Parabolas vs. Lines

![image-20230201204608921](C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230201204608921.png)

The important thing is the “shape” of our graph (i.e. parabolic vs. linear) Let us (for now) informally refer to the shape of our graph as the “orders of growth”.重要的是图形的“形状”（即抛物线与线性）。让我们（现在）非正式地将图形的形状称为“增长顺序”。

### Returning to Duplicate Finding

Returning to our original goals of characterizing the runtimes of `dup1` vs. `dup2`

- They should be **simple** and **mathematically rigorous.**
- They should also clearly demonstrate the **superiority of dup2 over dup1.**

We’ve accomplished the second task! We were able to clearly see that `dup2` performed better than `dup1`. However, we didn’t do it in a very simple or mathematically rigorous way.我们完成了第二项任务！我们能够清楚地看到，“dup2”比“dup1”表现得更好。然而，我们并没有以非常简单或数学严谨的方式来做这件事。

We did however talk about how `dup1` performed “like” a parabola, and `dup2` performed “like” a line. Now, we’ll be more formal about what we meant by those statements by applying the four simplifications.然而，我们确实讨论了“dup1”如何“像”抛物线，“dup2”如何“象”直线。现在，我们将通过应用四个简化来更正式地解释这些语句的含义。

#### Intuitive(直觉的) Simplification 1: Consider only the Worst Case

==在比较算法时，我们通常只关心最坏的情况（尽管我们将在本课程后面看到一些例外情况）==。

**Checkpoint**: Order of Growth Identification

Consider the counts for the algorithm below. What do you expect will be the order of growth of the runtime for the algorithm?

<img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230201210421906.png" alt="image-20230201210421906" style="zoom: 45%;" />

#### Intuitive Simplification 2: Restrict Attention to One Operation 将注意力限制在一项操作上

==Pick some representative operation to act as a proxy for overall runtime.选择一些具有代表性的操作作为整个运行时的代理。==

- ==Good choice: `increment`, or **less than** or **equals** or **array accesses**==
- ==Bad choice: **assignment of** `j = i + 1`, or `i = 0 `==

The operation we choose can be called the “**cost model**.”我们选择的操作可以称为“**成本模型**”

#### Intuitive Simplification 3: Eliminate Low Order Terms 消除低阶

Ignore lower order terms!

**Sanity check合格性检查**: Why does this make sense? (Related to the checkpoint above!)

#### Intuitive Simplification 4: Eliminate Multiplicative Constants 消除乘法常数

Ignore multiplicative constants.

- Why? No real meaning!
- Remember that by choosing a single representative operation, we already “threw away” some information

### Simplification Summary

- **Only consider the worst case.**
- **==Pick a representative operation (aka: cost model)==**
- **Ignore lower order terms**
- **Ignore multiplicative constants.**

------

**Checkpoint**: Apply these four steps to `dup2`, given the following tables.

<img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230201210811611.png" alt="image-20230201210811611" style="zoom:50%;" />

------

#### **Summary of our (Painful) Analysis Process** 我们（痛苦的）分析过程总结

- Construct a table of exact counts of all possible operations (takes lots of effort!)构建一个所有可能操作的精确计数表（需要大量努力！）
- Convert table into worst case order of growth using 4 simplifications.使用4个简化将表转换为最坏的增长顺序。

But, what if we just avoided building the table from the get-go, by using our simplifications from the very start?**但是，如果我们==从一开始就通过使用我们的简化来避免构建表呢==？**

### Simplified Analysis Process

Rather than building the entire table, we can instead:而不是构建整个表，我们可以：

- Choose our cost model (representative operation we want to count).选择我们的成本模型（我们要计算的代表性运营）。
- Figure out the order of growth for the count of our representative operation by either:通过以下任一方法计算我们的代表性运营数量的增长顺序：
  - Making an exact count, and discarding unnecessary pieces进行精确计数，并丢弃不必要的碎片
  - Or, using intuition/inspection to determine orders of growth (comes with practice!)或者，使用直觉/检查来确定增长顺序（伴随实践！）

We’ll now re-analyze `dup1` using this process.

#### Analysis of Nested For Loops: Exact Count

Find order of growth of worst case runtime of `dup1`.

```java
int N = A.length;
for (int i = 0; i < N; i += 1)
   for (int j = i + 1; j < N; j += 1)
      if (A[i] == A[j])
         return true;
return false;
```

**Cost model**: number of == operations

Given the following chart, how can we determine how many == occurs? The y axis represents each increment of i, and the x access represents each increment of j. 

Cost = 1 + 2 + 3 + ... + (N - 1) = N(N - 1) / 2 

#### Analysis of Nested For Loops: ==Geometric Argument 几何学论点==

<img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230201211608497.png" alt="image-20230201211608497" style="zoom: 50%;" />

### Formalizing Order of Growth 形式化增长顺序

Given some function, Q(N), we can apply our last two simplifications to get the order of growth of Q(N).

- Reminder: last two simplifications are dropping lower order terms and multiplicative constants.
- Example: <img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230201211725768.png" alt="image-20230201211725768" style="zoom:33%;" />
- After applying the simplifications for order of growth, we get: <img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230201211735930.png" alt="image-20230201211735930" style="zoom:33%;" />

Now, we’ll use the formal notation of “Big-Theta" to represent how we’ve been analyzing our code.

<img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230201211758831.png" alt="image-20230201211758831" style="zoom:33%;" />

---

### Big-Theta

<img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230201211941755.png" alt="image-20230201211941755" style="zoom:33%;" />

### Big O

<img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230201212101869.png" alt="image-20230201212101869" style="zoom:33%;" />

<img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230201212107491.png" alt="image-20230201212107491" style="zoom:50%;" />

==**Observe that this is a looser condition than Big Theta since Big O does not care about the lower bound 观察到这是一个比Big Theta更宽松的条件，因为Big O不关心下限**==

### Summary

- Given a piece of code, we can express its runtime as a function R(N) 给定一段代码，**我们可以将其运行时表示为函数R（N）**

  - N is some **property** of the input of the function
  - i.e. oftentimes, N represents the **size** of the input

- Rather than finding R(N) exactly, we instead usually only care about the **order of growth** of R(N).

- One approach (not universal):

  - Choose a representative operation
  - Let C(N) = count of how many times that operation occurs, as a function of N.

  <img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230201212235784.png" alt="image-20230201212235784" style="zoom: 50%;" />
  
  

# 8.3 Asymptotics II

### A first example with Loops

现在我们已经看到了一些运行时分析，让我们通过一些更困难的示例。**我们的目标是对运行时分析中涉及的模式和方法进行一些实践。**这可能是一个棘手的想法，所以练习越多越好。

Last time, we saw the function dup1, that checks for the first time any entry is duplicated in a list:

```java
int N = A.length;
for (int i = 0; i < N; i += 1)
   for (int j = i + 1; j < N; j += 1)
      if (A[i] == A[j])
         return true;
return false;
```

We have two ways of approaching our runtime analysis: **first, by counting the number of operations; second, a geometric argument.**

第一种方法：由于主要的重复操作是比较，我们将计算必须发生的==操作的数量。第一次通过外循环时，内循环将运行N-1次。第二次，它将运行N-2次。然后N-3…在最坏的情况下，我们必须遍历每个条目（外循环运行N次）。

<img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230202112418124.png" alt="image-20230202112418124" style="zoom: 50%;" />

Second method: **==We can also approach this from a geometric view.==** Let's draw out when we use == operations in the grid of i,j combinations:第二种方法：我们也可以从几何角度来处理这个问题。当我们在i，j组合的网格中使用==操作时，让我们画出：

![dup_1_geometry](https://joshhug.gitbooks.io/hug61b/content/assets/dup1_square.png)

<img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230202112511496.png" alt="image-20230202112511496" style="zoom:50%;" />

## Loop Example 2

Let's look at a more involved example next. Consider the following function, with similar nested for loops:

```java
public static void printParty(int N) {
   for (int i = 1; i <= N; i = i * 2) {
      for (int j = 0; j < i; j += 1) {
         System.out.println("hello");   
         int ZUG = 1 + 1;
      }
   }
}
```

The first loop advances ==by *multiplying* `i` by 2 each time==. The inner loop runs from 0 to the current value of `i`. The two operations inside the loop are both constant time, so let's approach this by asking "how many times does this print out "hello" for a given value of N?"

我们上面的可视化工具帮助我们看到了dup1的运行时，所以让我们在这里使用类似的方法。我们将为嵌套的for循环布置网格，然后跟踪下面给定N所需的打印语句总数。

<img src="https://joshhug.gitbooks.io/hug61b/content/assets/loops2_4.png" alt="loop diagram 4" style="zoom:50%;" />

<img src="https://joshhug.gitbooks.io/hug61b/content/assets/loops2_graph.png" alt="graph" style="zoom:50%;" />

Therefore, the runtime (by definition) must also be linear!

Let's look at this another way as well:

<img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230202112931438.png" alt="image-20230202112931438" style="zoom:67%;" />

And by removing lesser terms and multiplicative constants, we know that 2N - 1 is in the linear family.

We can also see this on our graph by plotting 2N:

<img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230202113818783.png" alt="image-20230202113818783" style="zoom:50%;" />

<img src="https://joshhug.gitbooks.io/hug61b/content/assets/loops2_graph2.png" alt="graph" style="zoom:50%;" />

> **==此例中，增长是线性的==**

## There is no magic shortcut :(

It would be really nice if there were some magic way to look at an algorithm and just *know* its runtime. It would be super convenient if all nested for loops were N^2. They're not. And we know this because we just did two nested for loop examples above, each with different runtimes.

In the end, there is no shortcut to doing runtime analysis. It requires careful thought. But there are a few useful techniques and things to know.

**Techniques:**

- *Find exact sum*
- *Write out examples*
- *Draw pictures*

We used each of these in the examples above.

**Sum Things to Know** Here are two important sums you'll see quite often, and should remember:

---

![image-20230202114058532](C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230202114058532.png)

---

You saw both of these above, and they'll return again and again in runtime analysis.

> 没有捷径， 只能count， 或许画图然后凭借几何直观是所谓的“捷径”之一

## Recursion

Now that we've done a couple of nested for loops, let's take a look at a recursive example. Consider the function `f3`:

```java
public static int f3(int n) {
   if (n <= 1) 
      return 1;
   return f3(n-1) + f3(n-1);
}
```

<img src="https://joshhug.gitbooks.io/hug61b/content/assets/asymptotics2_tree.png" alt="tree recursion" style="zoom: 50%;" />

Now, let's think about the runtime. We can notice that every time we add one to N, we double the amount of work that has to be done:现在，让我们考虑一下运行时。我们可以注意到，每次我们将N加1，我们就将需要完成的工作量加倍：

<img src="https://joshhug.gitbooks.io/hug61b/content/assets/asymptotics2_tree2.png" alt="img" style="zoom:50%;" />

<img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230202165402354.png" alt="image-20230202165402354" style="zoom: 33%;" />

==每个N + 1， 都会导致工作量加倍，再加1， 所以我们可以得出这个关系式子(**其中的一种方法是根据递推式得出复杂度!!!!!!!**)==

==`C(N) = 2C(N - 1) + 1`==

## Binary Search

> ==如下图, 推导出log(N)的过程是 N / 2^c = 1 ---> c = log(N)==

<img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230202171636950.png" alt="image-20230202171636950" style="zoom: 33%;" />

==**One cool fact to wrap up with: Log time is super good! It's almost as fast as constant time, and way better than linear time. This is why we like binary search, rather than stepping one by one through our list and looking for the right thing.	总结一个很酷的事实：log(N)非常好！它几乎和恒定时间一样快，而且比线性时间好得多。这就是为什么我们喜欢二进制搜索，而不是一步一步地浏览我们的列表并寻找正确的东西。**==

To show this concretely:

| N                   | log2(N) | Typical runtime (nanoseconds(纳秒)) |
| :------------------ | :------ | :---------------------------------- |
| 100                 | 6.6     | 1                                   |
| 100,000             | 16.6    | 2.5                                 |
| 100,000,000         | 26.5    | 4                                   |
| 100,000,000,000     | 36.5    | 5.5                                 |
| 100,000,000,000,000 | 46.5    | 7                                   |

## Merge Sort

> ==**merge sort 是 `O(nlog(n))`**==

Let's introduce one other idea here: **==arbitrary units of time==**. While the exact time something will take will depend on the machine, on the particular operations, etc., we can get a general sense of time through our arbitrary units (AU).、

<img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230203000543690.png" alt="image-20230203000543690" style="zoom: 33%;" />

**选择排序是缓慢的, merge是快速的(线性的), 我们如何结合起来?**

<img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230203001456055.png" alt="image-20230203001456055" style="zoom:33%;" />

<img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230203001508530.png" alt="image-20230203001508530" style="zoom:33%;" />

<img src="https://joshhug.gitbooks.io/hug61b/content/assets/timetable.png" alt="timing_table_for_runtimes" style="zoom: 67%;" />

==**O(nlog(n)) 是远远好于O(n ^ 2)的**==

**==O(nlog(n))并没有比O(n)好太多==**

### Wrapup

**Takeaways**

- There are no magic shortcuts for analyzing code runtime.

- In our course, it’s OK to do exact counting or intuitive analysis.

- Know how to sum 1 + 2 + 3 + ... + N and 1 + 2 + 4 + ... + N.

- We won’t be writing mathematical proofs in this class.

- Many runtime problems you’ll do in this class resemble one of the five problems from today. See textbook, study guide, and discussion for more practice.

- This topic has one of the highest skill ceilings of all topics in the course. All the tools are here, but **practice** is your friend!

- Different solutions to the same problem, e.g. sorting, may have different runtimes (with big enough differences for the runtime to go from impractical to practical!).

  <img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230203001754717.png" alt="image-20230203001754717" style="zoom:50%;" />

希望这组示例为运行时分析的技术和模式提供了一些良好的实践。记住，没有神奇的捷径，但你必须有工具来解决问题。继续分析！！



# 8.4 Omega and Amortized Analysis(摊销分析)

In this section, we'll wrap up our discussion of asymptotics. **Much of this material won't be expanded on until later in the course.** This section expands on the concept of Big O and introduces Omega. We'll also explore the idea of amortized runtimes and their analysis. Finally, we'll end on empirical analysis of runtimes and a sneak preview of complexity theory.在本节中，我们将结束对渐近线的讨论**直到课程后期，这些材料中的大部分内容才会展开。**本节将扩展大O的概念并介绍Omega。我们还将探讨摊销运行时的概念及其分析。最后，我们将以运行时的经验分析和复杂性理论的预览为结尾。

## Runtime Analysis Subtleties(微妙)

**==有些情况中， 是无法用`θ() `表示的, 只能写出最差的情况`O()`==** ,例如:

```java
public boolean dup4(int[] a) {
    int N = a.length;
    for (int i = 0; i < N; i += 1) {
        for (int j = i + 1; j < N; j += 1) {
            if (a[i] == a[j]) {
                return true;
            }
        }
    }
    return false;
}
```

## Big O Abuse

<img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230203104206443.png" alt="image-20230203104206443" style="zoom: 15%;" />

==θ可以给我们更多的信息, 同样的表述, 我们可以用 the worst case runtime is θ()==

**Note:** Big O is NOT the same as "worst case". But it is often used as such.

To summarize the usefulness of Big O:

- It allows us to make simple statements without case qualifications, in cases where the runtime is different for different inputs.
- Sometimes, for particularly tricky problems, we (the computer science community) don't know the exact runtime, so we may only state an upper bound.
- It's a lot easier to write proofs for Big O than Big Theta, like we saw in finding the runtime of mergesort in the previous chapter. This is beyond the scope of this course.

## Big Omega (Ω)

为了完善我们对运行时的理解，我们还要定义BigO的补充，以描述下限。

<img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230203125933383.png" alt="image-20230203125933383" style="zoom:50%;" />

**==Big Theta可以被非正式地认为是运行时相等，Big O代表“小于或等于”，但Big Omega可以被认为是“大于或等于”。==**

Ω的应用 : 

+ **==如果我们同时证明了`R(N) = O(f(N))` 和 `R(N) = Ω(f(N))` 那么有 `R(N) = θ(f(N))`==** 
+ It's used to prove the difficulty of a problem. 通常用来证明一个问题的难度

<img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230203130735383.png" alt="image-20230203130735383" style="zoom: 50%;" />

## Amortized Analysis (Intuitive Explanation) 摊销分析（直观解释）

### Grigometh's Urn 格里戈麦斯的瓮

Grigometh is a demon dog that looks a bit spooky. He offers you the ability to appear to horses in their dreams, just like how he sometimes appears in your dreams and midterms. However, in return for this ability, you must periodically offer him urnfuls of hay, as tribute. He gives you two payment options: 格里戈麦斯是一只看起来有点吓人的恶魔狗。他让你有能力在马的梦中出现，就像他有时出现在你的梦中和期中一样。然而，作为对这种能力的回报，你必须定期向他提供几把干草作为贡品。他给你两种付款方式：

- Choice 1: Every day, Grigometh eats 3 bushels of hay from your urn.
- Choice 2: Grigometh eats exponentially more hay over time, but comes exponentially less frequently. (即吃的量和吃的频率都指数级别地上涨) Specifically:
  - On day 1, he eats 1 bushel of hay (total 1)
  - On day 2, he eats 2 additional bushels of hay (total 3)
  - On day 4, he eats 4 additional bushels of hay (total 7)
  - On day 8, he eats 8 additional bushels of hay (total 15)

你想养成一个习惯，每天在你的瓮里放固定数量的干草。对于每个付款计划，您每天必须投入多少干草？哪个更便宜？

作为第一选择，你必须每天在瓮里放3蒲式耳的干草。然而，事实证明，第二种选择有点便宜！你每天只需在瓮里放2蒲式耳干草就可以脱身。（试着说服自己为什么这是真的——这样做的一个方法是写下每天之后你贡献的干草总量。你会注意到，每当格里戈麦斯来吃他的干草点心时，在他吃饱后，你的瓮里总会多放一蒲式耳。整洁。）

==Bushels aside, notice here that Grigometh's hay consumption per day is effectively constant, and in choice 2, we can describe this situation as **amortized constant** hay consumption.抛开灌木不谈，请注意格里戈麦斯每天的干草消耗量实际上是恒定的，在选择2中，我们可以将这种情况描述为**摊销的恒定**干草消耗量。==

### AList Resizing and Amortization

事实证明，格里戈麦斯的干草困境与AList在课程初期调整大小非常相似。回想一下，在基于数组的列表的实现中，当我们对基础数组已满的AList调用add方法时，我们需要调整数组的大小。换句话说，add方法在满时必须创建一个更大的新数组，复制旧元素，然后最后添加新元素。我们的新阵列应该多大？回想一下以下两个实现：

Implementation 1

```java
public void addLast(int x) {
  if (size == items.length) {
    resize(size + RFACTOR);
  }
  items[size] = x;
  size += 1;
}
```

Implementation 2

```java
public void addLast(int x) {
  if (size == items.length) {
    resize(size * RFACTOR);
  }
  items[size] = x;
  size += 1;
}
```

第一个实现结果是糟糕透顶。当阵列填满时，每次添加新元素时，必须将整个阵列复制到新的阵列中。另一方面，我们称之为几何尺寸调整的第二个实现工作得很好。事实上，Python列表就是这样实现的。

Let's look into the runtime of implementation 2 in more detail. Let RFACTOR be 2. When the array is full, resize doubles its size. Most add operations take Θ(1)Θ(1) time, but some are very expensive, and linear to the current size. However, if we average out the cost of expensive adds with resize over all the adds that are cheap, and given that expensive adds with happen half as frequently every time it happens, ==it turns out that **on average**, the runtime of add is Θ(1)==. We'll prove this in the next section. In the meantime, here's a graph to illustrate this

![amortized_add_operations](https://joshhug.gitbooks.io/hug61b/content/assets/amortized_adds.png)

> cumulative : 累计的

### Amortized Analysis (Rigorous Explanation) 摊销分析（严格解释）

这里分三个步骤对摊销分析进行更严格的检查：

1. Pick a cost model (like in regular runtime analysis) 选择成本模型（如常规运行时分析）
2. Compute the average cost of the i'th operation 计算第i次操作的平均成本
3. Show that this average (amortized) cost is bounded by a constant. 表明该平均（摊余）成本受常数限制。

Suppose that initially, our ArrayList contains a length-1 array. Let's apply these three steps to ArrayList resizing: 假设最初，ArrayList包含一个长度为1的数组。让我们将这三个步骤应用于调整ArrayList大小：

1. For our cost model, we'll only consider array reads and writes. (You could also include other operations into your cost model, such as array creation and the cost of filling in default array values. But it turns out that these will all yield the same result.) 对于我们的成本模型，我们只考虑阵列读写。（您还可以在成本模型中包含其他操作，例如数组创建和填充默认数组值的成本。但事实证明，这些操作都会产生相同的结果。）
2. Let's compute the cost of a sequence of array adds. Suppose we had the following code and accompanying diagram:让我们计算一系列数组加法的成本。假设我们有以下代码和附图：

TODO: image

- x.add(0) performs 1 write operation. No resizing. Total: 1 operation
- x.add(1) resizes and copies the existing array (1 read, 1 write), and then writes the new element. Total: 3 operations
- x.add(2) resizes and copies the existing array (2 reads, 2 writes), and then writes the new element. Total: 5 operations
- x.add(3) does not resize, and only writes the new element. Total: 1 operations
- x.add(4) resizes and copies the existing array (4 reads, 4 writes), and then writes the new element. Total: 9 operations

It's easier to keep track of this in a table:

| Insert #         | 0    | 1    | 2    | 3    | 4    | 5    | 6    | 7    | 8    | 9    | 10   | 11   | 12   | 13   |
| :--------------- | :--- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| a[i] write cost  | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    |
| Resize/copy cost | 0    | 2    | 4    | 0    | 8    | 0    | 0    | 0    | 16   | 0    | 0    | 0    | 0    | 0    |
| Total cost for # | 1    | 3    | 5    | 1    | 9    | 1    | 1    | 1    | 17   | 1    | 1    | 1    | 1    | 1    |
| Cumulative cost  | 1    | 4    | 9    | 10   | 19   | 20   | 21   | 22   | 39   | 40   | 41   | 42   | 43   | 44   |

那个么，一系列加法运算的平均成本是多少？对于13次添加，每次添加的平均成本为44/13=3.1444/13=3.14。但对于前8次添加，每次添加的平均成本为39/8=4.87539/8=4.875。

1. Is the average (amortized) cost bounded by a constant? It seems like it might be bounded by 5. But just by looking at the first 13 adds, we cannot be completely sure. 平均（摊余）成本是否受常数限制？看起来它可能以5为界。但仅仅看前13个补充，我们不能完全确定。

<img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230203132649194.png" alt="image-20230203132649194" style="zoom:50%;" />

> 在这个例子中, 是摊销下来是O(1)常数

By looking at the trend, the potential should never be negative (proof for this is omitted). Intuitively, for high-cost operations, we use the previous low-cost operations to store up potential.通过观察趋势，潜力永远不应该是负的（省略了这方面的证明）。直观地说，对于高成本运营，我们使用以前的低成本运营来存储潜力。

Finally, we've shown that ArrayList add operations are indeed amortized constant time. Geometric resizing (multiplying by the RFACTOR) leads to good list performance. 最后，我们已经证明ArrayList添加操作确实是按固定时间摊销的。几何调整大小（乘以RFACTOR）可获得良好的列表性能。

**Summary**

- Big O is an upper bound ("less than or equals")
- Big Omega is a lower bound ("greater than or equals")
- Big Theta is both an upper and lower bound ("equals")
- Big O does NOT mean "worst case". We can still describe worst cases using Big Theta
- Big Omega does NOT mean "best case". We can still describe best cases using Big Theta
- Big O is sometimes colloquially used in cases where Big Theta would provide a more precise statement
- ==Amortized analysis provides a way to prove the average cost of operations.摊销分析提供了一种证明平均运营成本的方法。==

<img src="C:\Users\weiziheng\AppData\Roaming\Typora\typora-user-images\image-20230203135109737.png" alt="image-20230203135109737" style="zoom:50%;" />
